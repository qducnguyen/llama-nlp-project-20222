{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"xf3pUNyVO3WS"},"source":["# Alpaca-7B-LoRA demo by Group 13 NLP Project\n","\n","Adopted from [LLM-As-Chatbot](https://github.com/deep-diver/LLM-As-Chatbot)\n","\n","If possible, please run the notebook on [Kaggle]( https://www.kaggle.com/code/quangduc0703/alpaca-7b-lora-demo) \n"]},{"cell_type":"markdown","metadata":{},"source":["\n","## Check GPU's Memory Capacity\n","\n","By running `nvidia-smi` command, you can find out the GPU's memory capacity on the current system. \n","\n","With the standard GPU instance (___P100___) which is free on Kaggle, we could run the model easily."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-29T02:12:24.008397Z","iopub.status.busy":"2023-06-29T02:12:24.008129Z","iopub.status.idle":"2023-06-29T02:12:24.985444Z","shell.execute_reply":"2023-06-29T02:12:24.984291Z","shell.execute_reply.started":"2023-06-29T02:12:24.008373Z"},"id":"L2MoM27rfaKK","outputId":"53175950-3269-4296-9425-3652c81ce9b7","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Jun 29 02:12:24 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"N0MDD9TuPTfJ"},"source":["# Clone the repository"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-29T02:12:28.407771Z","iopub.status.busy":"2023-06-29T02:12:28.407309Z","iopub.status.idle":"2023-06-29T02:12:30.816590Z","shell.execute_reply":"2023-06-29T02:12:30.815398Z","shell.execute_reply.started":"2023-06-29T02:12:28.407728Z"},"id":"a_i5DKBNnzAK","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'llama-nlp-project-20222'...\n","remote: Enumerating objects: 101, done.\u001b[K\n","remote: Counting objects: 100% (101/101), done.\u001b[K (92/101)\u001b[K\n","remote: Compressing objects: 100% (50/50), done.\u001b[K\n","remote: Total 101 (delta 48), reused 96 (delta 47), pack-reused 0\u001b[K\n","Receiving objects: 100% (101/101), 11.32 MiB | 22.47 MiB/s, done.\n","Resolving deltas: 100% (48/48), done.\n","/kaggle/working/llama-nlp-project-20222/src\n"]}],"source":["!git clone https://github.com/qducnguyen/llama-nlp-project-20222"]},{"cell_type":"markdown","metadata":{"id":"HUuzxWGuPYLq"},"source":["# Move into the directory of the cloned repository"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-28T17:24:41.329396Z","iopub.status.busy":"2023-06-28T17:24:41.329003Z","iopub.status.idle":"2023-06-28T17:24:41.338047Z","shell.execute_reply":"2023-06-28T17:24:41.336897Z","shell.execute_reply.started":"2023-06-28T17:24:41.329361Z"},"id":"wR-M8u7gsQqg","outputId":"eb7b24ba-10e4-46d5-cf8f-852d9fac8170","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/LLM-As-Chatbot\n"]}],"source":["%cd llama-nlp-project-20222/src"]},{"cell_type":"markdown","metadata":{"id":"XG8oy7BBPdMh"},"source":["# Install dependencies"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-29T02:12:46.029064Z","iopub.status.busy":"2023-06-29T02:12:46.028664Z","iopub.status.idle":"2023-06-29T02:14:24.539184Z","shell.execute_reply":"2023-06-29T02:14:24.537790Z","shell.execute_reply.started":"2023-06-29T02:12:46.029010Z"},"id":"moN-15x_ifHE","outputId":"a7ec61ff-28cb-4ac4-a0ca-6a5cba060579","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -q -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"Cr3bQkSePfrG"},"source":["# Run the application\n","\n","Please ignore the warning and go to the link in \"Running on public URL: https://[].gradio.live\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-29T02:14:53.757584Z","iopub.status.busy":"2023-06-29T02:14:53.757202Z","iopub.status.idle":"2023-06-29T02:24:02.934490Z","shell.execute_reply":"2023-06-29T02:24:02.933302Z","shell.execute_reply.started":"2023-06-29T02:14:53.757549Z"},"id":"y3qpzBw2jMHq","trusted":true},"outputs":[],"source":["!python app.py --share"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
